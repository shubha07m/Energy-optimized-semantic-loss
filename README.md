![alt text](https://github.com/shubha07m/semantic_testing/blob/main/dogs.png)


We are experimenting with various transformer models to observe the effect of model selection on semantic understanding. We have shown how with or without a background and selection of different pre-trained transformer models can affect the similarity comparison. We are benchmarking detailed resource consumption during inference. We have also performed similar experiments for textual similarity.
